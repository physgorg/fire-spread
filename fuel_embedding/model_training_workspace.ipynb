{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de69b55-bb83-4874-a91d-758b6b99d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from utils import load\n",
    "from attrdict import AttrDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa42bc-a095-4206-aab1-5a757903298b",
   "metadata": {},
   "source": [
    "### Load dataset and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97b7031-0c1e-4627-b966-f861aa69656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_meta = pd.read_csv('fuel_autoencoder/landfire_metadata.csv')\n",
    "lf_meta.drop(index = 0,inplace= True)\n",
    "\n",
    "landfire_fuel_classes = dict(zip(lf_meta['VALUE'],lf_meta['FBFM40']))\n",
    "\n",
    "kys = list(landfire_fuel_classes.keys())\n",
    "fuel_classes = {i:landfire_fuel_classes[x] for i,x in enumerate(kys)}\n",
    "fuel_class_map = {x:i for i,x in enumerate(kys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b54ffaf-b9c2-441f-8f08-a0c13a65976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = {row['FBFM40']:(row['R'],row['G'],row['B']) for i,row in lf_meta.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa56005f-2134-4e1b-86e5-dc98744c7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['train','test','val']\n",
    "data_loaders = {}\n",
    "for mode in modes:\n",
    "    tfrecord_path = f\"dataset/conus_west_fbfm40_{mode}.tfrecord\"\n",
    "    index_path = None\n",
    "    description = {\"fbfm\": \"float\"}\n",
    "    dataset = TFRecordDataset(tfrecord_path, index_path, description)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=2048)\n",
    "    data_loaders[mode] = loader\n",
    "    data_batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14048b-e24c-44f3-8a86-223fb976f6f6",
   "metadata": {},
   "source": [
    "### data processing funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261d91f5-eef3-490a-9983-869a582b9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_categories(value):\n",
    "    try:\n",
    "        return fuel_class_map[value]\n",
    "    except KeyError:\n",
    "        return float('nan')\n",
    "\n",
    "def get_pcts(arr): # takes (B,H,W) array\n",
    "    B,H,W = arr.shape\n",
    "    n_cats = len(kys)\n",
    "    res = torch.zeros((B,n_cats))\n",
    "    for i,img in enumerate(arr):\n",
    "        for k,cat in enumerate(kys):\n",
    "            res[i,k] = torch.sum(arr[i] == cat).item()/(H*W)\n",
    "    return res\n",
    "\n",
    "def process_batch(data_batch,onehot = False):\n",
    "    data = data_batch['fbfm'].clone()\n",
    "    data = data.reshape((data.shape[0],16,16))\n",
    "    labels = get_pcts(data)\n",
    "    data.apply_(replace_categories)\n",
    "    if onehot:\n",
    "        data = F.one_hot(data.long(),num_classes = len(kys)).float()\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a25ab-2b63-4c22-87f9-05eb2a89d227",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512044b0-e388-476a-937b-3f1bb05200af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,labels = process_batch(data_batch,onehot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d9dd5a6-4cd8-4b4d-9d4e-2e08a85a2817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af476a-6228-4f77-b1f5-3fbba32fcbb9",
   "metadata": {},
   "source": [
    "### Model definition/development workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35010761-47bd-442e-9ecb-ea08cae67166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels=45,\n",
    "        input_height=16,\n",
    "        input_width=16,\n",
    "        conv_channels=[64, 32,32],\n",
    "        kernel_sizes=[3, 3,3],\n",
    "        strides=[1, 1,1],\n",
    "        paddings=[1, 1,1],\n",
    "        pooling='max',\n",
    "        pool_kernels=[2, 2,2],\n",
    "        fc_hidden_dims=[32,16,8],\n",
    "        n_H=4,\n",
    "        activation=nn.ReLU()\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.pool_layers = nn.ModuleList()\n",
    "        in_channels = input_channels\n",
    "        H_in, W_in = input_height, input_width\n",
    "\n",
    "        # Define convolutional and pooling layers\n",
    "        for i, (out_channels, kernel_size, stride, padding) in enumerate(\n",
    "            zip(conv_channels, kernel_sizes, strides, paddings)\n",
    "        ):\n",
    "            # Convolutional layer\n",
    "            conv = nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding\n",
    "            )\n",
    "            self.conv_layers.append(conv)\n",
    "\n",
    "            # Update spatial dimensions after convolution\n",
    "            H_in = self._compute_output_dim(H_in, kernel_size, stride, padding)\n",
    "            W_in = self._compute_output_dim(W_in, kernel_size, stride, padding)\n",
    "\n",
    "            # Pooling layer\n",
    "            if pooling == 'max':\n",
    "                pool = nn.MaxPool2d(kernel_size=pool_kernels[i])\n",
    "            elif pooling == 'avg':\n",
    "                pool = nn.AvgPool2d(kernel_size=pool_kernels[i])\n",
    "            else:\n",
    "                pool = None\n",
    "            self.pool_layers.append(pool)\n",
    "\n",
    "            # Update spatial dimensions after pooling\n",
    "            if pool is not None:\n",
    "                H_in = self._compute_output_dim(H_in, pool_kernels[i], pool_kernels[i], 0)\n",
    "                W_in = self._compute_output_dim(W_in, pool_kernels[i], pool_kernels[i], 0)\n",
    "\n",
    "            in_channels = out_channels\n",
    "\n",
    "        # Calculate the flattened feature dimension after convolutions\n",
    "        self.feature_dim = H_in * W_in * in_channels\n",
    "\n",
    "        # Define fully connected layers\n",
    "        fc_dims = [self.feature_dim] + fc_hidden_dims + [n_H]\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.fc_batch_norms = nn.ModuleList()\n",
    "        for i in range(len(fc_dims) - 1):\n",
    "            in_dim = fc_dims[i]\n",
    "            out_dim = fc_dims[i + 1]\n",
    "            self.fc_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if i < len(fc_dims) - 2:\n",
    "                # Add BatchNorm1d layer for all but the last FC layer\n",
    "                self.fc_batch_norms.append(nn.BatchNorm1d(out_dim))\n",
    "\n",
    "    def _compute_output_dim(self, size, kernel_size, stride, padding):\n",
    "        return (size + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Permute input to (B, C, H, W)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Apply convolutional and pooling layers\n",
    "        for conv_layer, pool_layer in zip(self.conv_layers, self.pool_layers):\n",
    "            x = self.activation(conv_layer(x))\n",
    "            if pool_layer is not None:\n",
    "                x = pool_layer(x)\n",
    "\n",
    "        # Flatten the output from convolutional layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Apply fully connected layers with batch normalization\n",
    "        for i, fc_layer in enumerate(self.fc_layers[:-1]):\n",
    "            x = fc_layer(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc_batch_norms[i](x)\n",
    "\n",
    "        # Output layer without batch normalization and activation\n",
    "        x = self.fc_layers[-1](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_H=4,\n",
    "        fc_hidden_dims=[8,16,32],\n",
    "        output_dim=45,\n",
    "        activation=nn.ReLU()\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Define fully connected layers\n",
    "        fc_dims = [n_H] + fc_hidden_dims + [self.output_dim]\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.fc_batch_norms = nn.ModuleList()\n",
    "        for i in range(len(fc_dims) - 1):\n",
    "            in_dim = fc_dims[i]\n",
    "            out_dim = fc_dims[i + 1]\n",
    "            self.fc_layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if i < len(fc_dims) - 2:\n",
    "                # Add BatchNorm1d layer for all but the last FC layer\n",
    "                self.fc_batch_norms.append(nn.BatchNorm1d(out_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (B, n_H)\n",
    "        # Apply fully connected layers with batch normalization\n",
    "        for i, fc_layer in enumerate(self.fc_layers[:-1]):\n",
    "            x = fc_layer(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.fc_batch_norms[i](x)\n",
    "            \n",
    "        # Output layer without batch normalization and activation\n",
    "        x = self.fc_layers[-1](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class fuel_autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(fuel_autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        output_vector = self.decoder(latent)\n",
    "        return output_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f30fe-1086-4934-b150-94c46ef37099",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb60ec5-0aac-4ee2-83f8-95470f74560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'example_run'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a33718-88b5-42a5-b44e-8215e8f29a56",
   "metadata": {},
   "source": [
    "#### Define and load the model from its configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ce1b5-8239-4b3d-8182-595ffb98fe17",
   "metadata": {},
   "source": [
    "* note to self: this final model was trained for 25 + 10 + 10 epochs, annealing LR to 1e-3 -> 1e-4 after the 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45b92fbb-ad19-463f-a8b1-2d37fb5eaacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'fuel_autoencoder_config' from /Users/gorg/Documents/ndws/fuel_embedding/fuel_autoencoder_config.py\n"
     ]
    }
   ],
   "source": [
    "config = AttrDict({\n",
    "    \"conv_channels\":[32, 32],\n",
    "    \"kernel_sizes\":[3, 3,3],\n",
    "    \"strides\":[1, 1,1],\n",
    "    \"paddings\":[1, 1,1],\n",
    "    \"pooling\":'max',\n",
    "    \"pool_kernels\":[2, 2,2],\n",
    "    \"encoder_hidden_dims\":[32,16],\n",
    "    \"latent_dim\":3,\n",
    "    \"decoder_hidden_dims\":[8,16,32],\n",
    "    \"weights_seed\":123,\n",
    "    \"learning_rate\":1e-3\n",
    "})\n",
    "\n",
    "model_config_file = 'fuel_autoencoder_config.py'\n",
    "autoencoder,name = load(model_config_file,config)\n",
    "\n",
    "with open(f'models/{run_name}.json','w') as json_file:\n",
    "    json.dump(config,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81acd458-6bea-40aa-9d7f-081d508d87e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fuel_autoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (activation): ReLU()\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Conv2d(45, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (pool_layers): ModuleList(\n",
       "      (0-1): 2 x MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (fc_layers): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (2): Linear(in_features=16, out_features=3, bias=True)\n",
       "    )\n",
       "    (fc_batch_norms): ModuleList(\n",
       "      (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (activation): ReLU()\n",
       "    (fc_layers): ModuleList(\n",
       "      (0): Linear(in_features=3, out_features=8, bias=True)\n",
       "      (1): Linear(in_features=8, out_features=16, bias=True)\n",
       "      (2): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (3): Linear(in_features=32, out_features=45, bias=True)\n",
       "    )\n",
       "    (fc_batch_norms): ModuleList(\n",
       "      (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a547d0e8-0d52-4bee-b0fa-22a0a229adbe",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9658d9f4-81a2-44c1-8d72-e7d5a8b19d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: : 445batch [10:22,  1.40s/batch, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 1: : 134batch [02:59,  1.34s/batch, loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0433\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: : 445batch [10:16,  1.38s/batch, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 2: : 134batch [03:01,  1.36s/batch, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0431\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: : 445batch [10:03,  1.36s/batch, loss=0.161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 3: : 134batch [02:57,  1.32s/batch, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0431\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: : 445batch [10:07,  1.37s/batch, loss=0.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 4: : 134batch [03:02,  1.36s/batch, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0429\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: : 445batch [10:14,  1.38s/batch, loss=0.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 5: : 134batch [02:58,  1.33s/batch, loss=0.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0429\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: : 445batch [10:12,  1.38s/batch, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 6: : 134batch [03:00,  1.35s/batch, loss=0.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0427\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: : 445batch [10:05,  1.36s/batch, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 7: : 134batch [02:59,  1.34s/batch, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0425\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: : 445batch [10:08,  1.37s/batch, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 8: : 134batch [03:00,  1.35s/batch, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0426\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: : 445batch [10:06,  1.36s/batch, loss=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 9: : 134batch [03:00,  1.34s/batch, loss=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0425\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: : 445batch [10:05,  1.36s/batch, loss=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Epoch 10: : 134batch [02:57,  1.33s/batch, loss=0.149]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0424\n",
      "Training complete\n",
      "Best Validation Loss: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the optimizer\n",
    "autoencoder.load_state_dict(best_model_wts)\n",
    "\n",
    "optimizer = optim.AdamW(autoencoder.parameters(), lr=1e-4)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('mps')\n",
    "autoencoder.to(device)\n",
    "\n",
    "best_model_wts = copy.deepcopy(autoencoder.state_dict())\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            autoencoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            autoencoder.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        with tqdm(data_loaders[phase], unit=\"batch\") as tepoch:\n",
    "            for batch in tepoch:\n",
    "                tepoch.set_description(f\"{phase.capitalize()} Epoch {epoch+1}\")\n",
    "\n",
    "                inputs,targets = process_batch(batch,onehot = True)\n",
    "                \n",
    "                inputs = inputs.to(device)  # Shape: (B, 16, 16, 45)\n",
    "                targets = targets.to(device)  # Shape: (B, 45)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = autoencoder(inputs)  # Shape: (B, 45)\n",
    "\n",
    "                    # Apply log_softmax to outputs\n",
    "                    log_probs = F.log_softmax(outputs, dim=-1)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = criterion(log_probs, targets)\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / 911360 # batch 2048 * 445 batches = 911360 \n",
    "\n",
    "        if phase == 'train':\n",
    "            train_losses.append(epoch_loss)\n",
    "        else:\n",
    "            val_losses.append(epoch_loss)\n",
    "\n",
    "            # Deep copy the model if it has better validation loss\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(autoencoder.state_dict())\n",
    "\n",
    "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "print('Training complete')\n",
    "print(f'Best Validation Loss: {best_loss:.4f}')\n",
    "\n",
    "# Load best model weights\n",
    "autoencoder.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ba33c93-5e2b-4303-b6f7-515e8f924041",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_wts,f'models/{run_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e7316c4-7b7c-43dc-b3db-e7ffc6636397",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses,label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_losses,label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(train_losses,label = 'train')\n",
    "plt.plot(val_losses,label = 'test')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890ce27-020f-45ad-a194-b0fd5bd5bbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
